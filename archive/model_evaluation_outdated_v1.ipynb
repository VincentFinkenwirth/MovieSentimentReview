{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T12:35:41.372914800Z",
     "start_time": "2025-01-30T12:35:38.848544100Z"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from tools.data_preprocess import load_data\n",
    "import joblib as jb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools.data_preprocess import load_data\n",
    "from tools.data_preprocess import ClassicPreprocessorSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model                                           Pipeline\n",
      "0        Random Forest  runs:/1b78da0367b94391b558810ba17b1660/best_pi...\n",
      "1          Naive Bayes  runs:/271da4ca0b3d4e35841b59cf2b77f015/best_pi...\n",
      "2                  SVM  runs:/07c752ee8102464fa82b73571383925c/best_pi...\n",
      "3  Logistic Regression  runs:/7e96a95d34094e22af7dad9afe84fc21/best_pi...\n",
      "4             CatBoost  runs:/32ba64e14eb94c278236aca7642a4e75/best_model\n",
      "5                 BERT  runs:/b2f1f4fb5fdf4076a7d0c5a1a97d156b/bert_model\n"
     ]
    }
   ],
   "source": [
    "# Best pipelines\n",
    "RANDOM_FOREST = 'runs:/1b78da0367b94391b558810ba17b1660/best_pipeline'\n",
    "NAIVE_BAYES = 'runs:/271da4ca0b3d4e35841b59cf2b77f015/best_pipeline'\n",
    "SVM = 'runs:/07c752ee8102464fa82b73571383925c/best_pipeline'\n",
    "LOG_REG = 'runs:/7e96a95d34094e22af7dad9afe84fc21/best_pipeline'\n",
    "CATBOOST = 'runs:/32ba64e14eb94c278236aca7642a4e75/best_model'\n",
    "BERT = 'runs:/b2f1f4fb5fdf4076a7d0c5a1a97d156b/bert_model'\n",
    "\n",
    "def save_model(name):\n",
    "    # Create dataframe of models and save it as model_v1.csv\n",
    "    models = pd.DataFrame({\"Model\": [\"Random Forest\", \"Naive Bayes\", \"SVM\", \"Logistic Regression\", \"CatBoost\", \"BERT\"],\n",
    "                           \"Pipeline\": [RANDOM_FOREST, NAIVE_BAYES, SVM, LOG_REG, CATBOOST, BERT]})\n",
    "    models.to_csv(f\"data/test_datasets/{name}\", index=False)\n",
    "    print(models)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-30T14:41:03.509776900Z",
     "start_time": "2025-01-30T14:41:03.493084900Z"
    }
   },
   "id": "1e64dc662dc9391f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444963\n",
      "Index(['id', 'reviewId', 'creationDate', 'criticName', 'isTopCritic',\n",
      "       'originalScore', 'reviewState', 'publicatioName', 'reviewText',\n",
      "       'scoreSentiment', 'reviewUrl'],\n",
      "      dtype='object')\n",
      "                                  id  reviewId creationDate       criticName  \\\n",
      "0                            beavers   1145982   2003-05-23  Ivan M. Lincoln   \n",
      "1                         blood_mask   1636744   2007-06-02    The Foywonder   \n",
      "2  city_hunter_shinjuku_private_eyes   2590987   2019-05-28     Reuben Baron   \n",
      "3  city_hunter_shinjuku_private_eyes   2558908   2019-02-14      Matt Schley   \n",
      "4                 dangerous_men_2015   2504681   2018-08-29        Pat Padua   \n",
      "\n",
      "   isTopCritic originalScore reviewState                 publicatioName  \\\n",
      "0        False         3.5/4       fresh  Deseret News (Salt Lake City)   \n",
      "1        False           1/5      rotten                  Dread Central   \n",
      "2        False           NaN       fresh                            CBR   \n",
      "3        False         2.5/5      rotten                    Japan Times   \n",
      "4        False           NaN       fresh                          DCist   \n",
      "\n",
      "                                          reviewText scoreSentiment  \\\n",
      "0  Timed to be just long enough for most youngste...       POSITIVE   \n",
      "1  It doesn't matter if a movie costs 300 million...       NEGATIVE   \n",
      "2  The choreography is so precise and lifelike at...       POSITIVE   \n",
      "3  The film's out-of-touch attempts at humor may ...       NEGATIVE   \n",
      "4  Its clumsy determination is endearing and some...       POSITIVE   \n",
      "\n",
      "                                           reviewUrl  \n",
      "0  http://www.deseretnews.com/article/700003233/B...  \n",
      "1  http://www.dreadcentral.com/index.php?name=Rev...  \n",
      "2  https://www.cbr.com/city-hunter-shinjuku-priva...  \n",
      "3  https://www.japantimes.co.jp/culture/2019/02/0...  \n",
      "4  http://dcist.com/2015/11/out_of_frame_dangerou...  \n"
     ]
    }
   ],
   "source": [
    "# Use new test data to evaluate models with reviews from a different source\n",
    "DATA_PATH_ROTTEN = \"data/rotten_tomatoes_movie_reviews.csv\"\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(DATA_PATH_ROTTEN)\n",
    "\n",
    "# Explore data\n",
    "print(len(data))\n",
    "print(data.columns)\n",
    "print(data.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:41:17.855091600Z",
     "start_time": "2025-01-29T17:41:15.019902800Z"
    }
   },
   "id": "ab16455e220ae1c9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Only keep the id, review and the sentiment\n",
    "data = data[[\"id\", \"reviewText\", \"scoreSentiment\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:41:17.920447600Z",
     "start_time": "2025-01-29T17:41:17.854090400Z"
    }
   },
   "id": "69e3ede2cce87927"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    0\n",
      "reviewText        69225\n",
      "scoreSentiment        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for empty values\n",
    "print(data.isnull().sum())\n",
    "# Remove empty values\n",
    "data = data.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:41:18.145772600Z",
     "start_time": "2025-01-29T17:41:17.922452500Z"
    }
   },
   "id": "6d9de983257f6b2f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoreSentiment\n",
      "POSITIVE    922510\n",
      "NEGATIVE    453228\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for number of positive and negative reviews\n",
    "print(data[\"scoreSentiment\"].value_counts())\n",
    "\n",
    "# Unbalanced dataset -> need to balance it for better evaluation\n",
    "# As we have enough data, we can downsample the positive reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:41:18.180354100Z",
     "start_time": "2025-01-29T17:41:18.145772600Z"
    }
   },
   "id": "a27c8a481e4f7929"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:41:18.180354100Z",
     "start_time": "2025-01-29T17:41:18.178849Z"
    }
   },
   "id": "f4ed2770c9db1fdd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  id  \\\n",
      "0                            beavers   \n",
      "1                         blood_mask   \n",
      "2  city_hunter_shinjuku_private_eyes   \n",
      "3  city_hunter_shinjuku_private_eyes   \n",
      "4                 dangerous_men_2015   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0  Timed to be just long enough for most youngste...   \n",
      "1  It doesn't matter if a movie costs 300 million...   \n",
      "2  The choreography is so precise and lifelike at...   \n",
      "3  The film's out-of-touch attempts at humor may ...   \n",
      "4  Its clumsy determination is endearing and some...   \n",
      "\n",
      "                                        preprocessed  sentiment  \n",
      "0  time long youngster brief attention span pack ...          1  \n",
      "1  matter movie cost million dollar good good bad...          0  \n",
      "2  choreography precise lifelike point wonder mov...          1  \n",
      "3  film touch attempt humor find hunt reason fran...          0  \n",
      "4       clumsy determination endear wildly entertain          1  \n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the data to create column with tokens and turn sentiment into binary\n",
    "def preprocess():\n",
    "    # Load preprocessor\n",
    "    preprocessor = jb.load(\"vectorizer/preprocessor.pkl\")\n",
    "    \n",
    "    \n",
    "    #Create preprocessed data as additional column named \"preprocessed\" for classical models\n",
    "    data[\"preprocessed\"] = preprocessor.transform(data[[\"reviewText\"]])\n",
    "    # turn preprocessed into string of tokens\n",
    "    data[\"preprocessed\"] = data[\"preprocessed\"].apply(lambda x: \" \".join(x)).astype(str)\n",
    "    \n",
    "    # Turn sentiment into binary\n",
    "    data[\"sentiment\"] = data[\"scoreSentiment\"].apply(lambda x: 1 if x == \"POSITIVE\" else 0)\n",
    "    data.drop(columns=[\"scoreSentiment\"], inplace=True)\n",
    "    \n",
    "    # Preprocessing may have created empty values -> check and remove them\n",
    "    # show  empty values\n",
    "    print(data.isnull().sum())\n",
    "    # delete empty values\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    print(data.head())\n",
    "    return data\n",
    "\n",
    "# Apply preprocessing (only once) to create data for classical models\n",
    "#data = preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:50:47.737735700Z",
     "start_time": "2025-01-29T17:41:18.181362Z"
    }
   },
   "id": "64d3ded4efc15f4f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "reviewText      0\n",
      "preprocessed    0\n",
      "sentiment       0\n",
      "dtype: int64\n",
      "id              object\n",
      "reviewText      object\n",
      "preprocessed    object\n",
      "sentiment        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save preprocessed data\n",
    "data.to_csv(\"data/test_datasets/rotten_tomatoes_movie_reviews_preprocessed_all.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:50:50.791035Z",
     "start_time": "2025-01-29T17:50:47.816902700Z"
    }
   },
   "id": "1a86d986be015272"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "1    200000\n",
      "0    200000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Sample data to balance the classes and reduce complexity\n",
    "def sampler(data, n_samples):\n",
    "    # Sample the positive reviews\n",
    "    positive = data[data[\"sentiment\"] == 1].sample(n=n_samples, random_state=42)\n",
    "    # Sample the negative reviews\n",
    "    negative = data[data[\"sentiment\"] == 0].sample(n=n_samples, random_state=42)\n",
    "    # Concatenate the samples\n",
    "    data = pd.concat([positive, negative])\n",
    "    data.to_csv(\"data/test_datasets/rotten_tomatoes_movie_reviews_preprocessed.csv\", index=False)\n",
    "    # Check the new distribution\n",
    "    print(data[\"sentiment\"].value_counts())\n",
    "    return data\n",
    "\n",
    "# Sample the data chose 200000 samples each to reduce complexity a little bit\n",
    "# data = sampler(data, 200000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-30T00:01:49.952178800Z",
     "start_time": "2025-01-30T00:01:48.785262600Z"
    }
   },
   "id": "bb5331ed41cba338"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Predict with models\n",
    "def predict_classical():\n",
    "    # Load models\n",
    "    rf = mlflow.sklearn.load_model(RANDOM_FOREST)\n",
    "    nb = mlflow.sklearn.load_model(NAIVE_BAYES)\n",
    "    svm = mlflow.sklearn.load_model(SVM)\n",
    "    log_reg = mlflow.sklearn.load_model(LOG_REG)\n",
    "    catboost = mlflow.sklearn.load_model(CATBOOST)\n",
    "    # Load preprocessed data\n",
    "    data = pd.read_csv(\"data/test_datasets/rotten_tomatoes_movie_reviews_preprocessed.csv\")\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    # Get predictions\n",
    "    data[\"rf_pred\"] = rf.predict(data[\"preprocessed\"])\n",
    "    data[\"nb_pred\"] = nb.predict(data[\"preprocessed\"])\n",
    "    data[\"svm_pred\"] = svm.predict(data[\"preprocessed\"])\n",
    "    data[\"log_reg_pred\"] = log_reg.predict(data[\"preprocessed\"])\n",
    "    data[\"catboost_pred\"] = catboost.predict(data[\"preprocessed\"])\n",
    "    \n",
    "    # Save data with predictions to csv\n",
    "    data.to_csv(\"data/test_datasets/rotten_predictions.csv\", index=False)\n",
    "\n",
    "# Apply prediction (only once)\n",
    "if \"rf_pred\" not in data.columns:\n",
    "    predict_classical()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-30T00:55:17.298036200Z",
     "start_time": "2025-01-30T00:41:22.347225900Z"
    }
   },
   "id": "498e75c8da2a22aa"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 13:37:21 INFO mlflow.transformers: 'runs:/b2f1f4fb5fdf4076a7d0c5a1a97d156b/bert_model' resolved as 'file:///C:/python/SpamDetection/mlruns/348789547859170955/b2f1f4fb5fdf4076a7d0c5a1a97d156b/artifacts/bert_model'\n",
      "2025/01/30 13:37:21 WARNING mlflow.transformers.model_io: Could not specify device parameter for this pipeline type.Falling back to loading the model with the default device.\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   id  \\\n",
      "0                       the_salvation   \n",
      "1                             belfast   \n",
      "2   standing_in_the_shadows_of_motown   \n",
      "3  1133712-reno_rebel_without_a_pause   \n",
      "4                   my_darling_vivian   \n",
      "\n",
      "                                          reviewText  \\\n",
      "0  A film reminiscent of a song that sounds famil...   \n",
      "1      Works gorgeously as an idealised memory play.   \n",
      "2  The brothers missed out on glory back in the d...   \n",
      "3  Even though the film runs a brief 71 minutes -...   \n",
      "4  A purely informational bio-doc that nonetheles...   \n",
      "\n",
      "                                        preprocessed  sentiment  rf_pred  \\\n",
      "0  film reminiscent song sound familiar offer ple...          1        1   \n",
      "1              work gorgeously idealised memory play          1        1   \n",
      "2  brother miss glory day help think cinematic la...          1        1   \n",
      "3  film run brief minute finish footage reno talk...          1        1   \n",
      "4  purely informational bio doc nonetheless tell ...          1        1   \n",
      "\n",
      "   nb_pred  svm_pred  log_reg_pred  catboost_pred  bert_pred  \n",
      "0        1         1             1              1          1  \n",
      "1        1         1             1              1          1  \n",
      "2        1         1             1              1          1  \n",
      "3        0         0             0              0          1  \n",
      "4        1         1             1              1          1  \n"
     ]
    }
   ],
   "source": [
    "# Add BERT scores seperately from the classical models as it is more complex\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def predict_bert():\n",
    "    # Load data\n",
    "    data = pd.read_csv(\"data/test_datasets/rotten_predictions.csv\")\n",
    "    # Load BERT model\n",
    "    bert = mlflow.transformers.load_model(BERT)\n",
    "    tokenizer = bert.tokenizer\n",
    "    model = bert.model\n",
    "    \n",
    "    \n",
    "    # Create a pipeline for sentiment analysis\n",
    "    bert_classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    # Predict with BERT\n",
    "    predictions = bert_classifier(data[\"reviewText\"].tolist())\n",
    "    # Extract sentiment from predictions\n",
    "    data[\"bert_pred\"] = [1 if x[\"label\"]==\"LABEL_1\" else 0 for x in predictions]\n",
    "    \n",
    "    # Save data with BERT predictions\n",
    "    data.to_csv(\"data/test_datasets/rotten_predictions_final.csv\", index=False)\n",
    "    print(data.head())\n",
    "\n",
    "predict_bert()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-30T12:57:56.102642300Z",
     "start_time": "2025-01-30T12:37:20.488105700Z"
    }
   },
   "id": "7391e57c94ae6e03"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 41\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# Apply evaluation\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(results)\n\u001B[0;32m     43\u001B[0m conf_mat \u001B[38;5;241m=\u001B[39m evaluate_labels()\n",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m, in \u001B[0;36mevaluate_metrics\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate_metrics\u001B[39m(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/test_datasets/rotten_predictions_final.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# Load data with predictions\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_csv(path)\n\u001B[0;32m      5\u001B[0m     results \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m model \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnb\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msvm\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlog_reg\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcatboost\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbert\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate models and create a table with the results including true positive, false positive, true negative, false negative\n",
    "def evaluate_metrics(path=\"data/test_datasets/rotten_predictions_final.csv\"):\n",
    "    # Load data with predictions\n",
    "    data = pd.read_csv(path)\n",
    "    results = []\n",
    "    for model in [\"rf\", \"nb\", \"svm\", \"log_reg\", \"catboost\", \"bert\"]:\n",
    "        y_true = data[\"sentiment\"]\n",
    "        y_pred = data[model + \"_pred\"]\n",
    "        \n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        \n",
    "        results.append([model, f1, accuracy, precision, recall])\n",
    "    \n",
    "    results = pd.DataFrame(results, columns=[\"Model\", \"F1\", \"Accuracy\", \"Precision\", \"Recall\"])\n",
    "    #results.to_csv(\"data/test_datasets/rotten_results.csv\", index=False)\n",
    "    return results\n",
    "\n",
    "def evaluate_labels(path=\"data/test_datasets/rotten_predictions_final.csv\"):\n",
    "    data = pd.read_csv(path)\n",
    "    results = []\n",
    "    for model in [\"rf\", \"nb\", \"svm\", \"log_reg\", \"catboost\", \"bert\"]:\n",
    "        y_true = data[\"sentiment\"]\n",
    "        y_pred = data[model + \"_pred\"]\n",
    "        \n",
    "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        \n",
    "        results.append([model, tp, fp, tn, fn])\n",
    "    \n",
    "    results = pd.DataFrame(results, columns=[\"Model\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "    #results.to_csv(\"data/test_datasets/rotten_confusion_matrix.csv\", index=False)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Apply evaluation\n",
    "results = evaluate_metrics()\n",
    "print(results)\n",
    "conf_mat = evaluate_labels()\n",
    "print(conf_mat)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T15:53:08.382695200Z",
     "start_time": "2025-02-04T15:53:08.281704700Z"
    }
   },
   "id": "5c0d2c855197cb3f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-29T17:50:51.249367500Z",
     "start_time": "2025-01-29T17:50:51.249367500Z"
    }
   },
   "id": "3e85c96355aee84b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
